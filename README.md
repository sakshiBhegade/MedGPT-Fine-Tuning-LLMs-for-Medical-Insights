# MedGPT-Fine-Tuning-LLMs-for-Medical-Insights
Executed the fine-tuning of a Large Language Model (LLM) using Hugging Face, achieving a training loss of 1.65 over 100 steps. U@lised advanced techniques like BitsAndBytes quan@sa@on and LoRA for efficiency. Trained on a medical dataset, processing 8.23 petaflops, and deployed for accurate, interac@ve medical queries.
